import OpenAI from 'openai';
import 'dotenv/config';
import { getPromptSystem } from './promptTemplate.js';

let openai = null;
if (process.env.OPENAI_API_KEY) {
  openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });
} else {
  console.warn('‚ö†Ô∏è OPENAI_API_KEY no configurado: GPT se simula.');
}

/**
 * Responde usando GPT. Si `openai` no est√° configurado, simula.
 * @param {string} mensajeVet  Texto del veterinario
 * @param {string} contextoExtra  Markdown con l√≠neas "- Producto ‚Ä¶" desde cat√°logo
 */
export async function responderConGPT(mensajeVet, contextoExtra = '') {
  // Seguridad de negocio: si no hay match en cat√°logo, no consultamos GPT.
  if (!contextoExtra) {
    return 'No encontr√© ese producto en el cat√°logo de KronenVet. ¬øPod√©s darme nombre comercial, marca o principio activo?';
  }

  if (!openai) {
    return `üõ†Ô∏è Simulaci√≥n KaIA:\n${mensajeVet}\n\nContexto:\n${contextoExtra}`;
  }

  try {
    const completion = await openai.chat.completions.create({
      model: 'gpt-4o-2024-05-13',
      messages: [
        { role: 'system', content: getPromptSystem({ contextoExtra }) },
        { role: 'user',   content: mensajeVet }
      ],
      temperature: 0.3
    });

    return completion.choices?.[0]?.message?.content || 'Sin respuesta del modelo.';
  } catch (error) {
    console.error('‚ùå Error OpenAI:', error);
    return 'No pude procesar tu consulta en este momento. Prob√° m√°s tarde.';
  }
}
